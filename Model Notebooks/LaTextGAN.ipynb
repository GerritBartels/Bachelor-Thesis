{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RddH5py1U8jQ"
      },
      "source": [
        "# **LaTextGAN**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nas1ClQlt9PA"
      },
      "source": [
        "## **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoJg2HIqIX5L"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import tensorflow as tf\n",
        "from tqdm.auto import tqdm \n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Adapt this variable to the path of the cloned repository\n",
        "path = \"YourPathHere\"\n",
        "\n",
        "# For importing custom modules\n",
        "import sys\n",
        "sys.path.append(f'{path}/Modules')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqDjAULEuTOO"
      },
      "source": [
        "Mount google drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxC5FSTksoKq",
        "outputId": "220dd3d9-cefe-4523-f2d6-3d81df57bd0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hyperparameters**"
      ],
      "metadata": {
        "id": "oM9IVZrKJ55g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 256 \n",
        "HIDDEN_SIZE = 1024     \n",
        "LEARNING_RATE_AE = 0.001\n",
        "LEARNING_RATE_GAN = 0.0001\n",
        "NUM_EPOCHS_AE = 20\n",
        "NUM_EPOCHS_GAN = 150\n",
        "BATCH_SIZE_AE = 256\n",
        "BATCH_SIZE_GAN = 256\n",
        "NUM_RESIDUAL_BLOCKS = 40\n",
        "GEN_UPDATE = 10 # number of steps before the generator is updated "
      ],
      "metadata": {
        "id": "DNKRUufZKAPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTkWVqMFubhV"
      },
      "source": [
        "## **Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import dataset_cleanup"
      ],
      "metadata": {
        "id": "gx7pdwcAiF_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIg9RDMWWP72"
      },
      "outputs": [],
      "source": [
        "data_path = f\"{path}/Dataset/news_data_preprocessed.csv\"\n",
        "min_sent_len=10\n",
        "max_sent_len=28\n",
        "\n",
        "cleaned_data, max_seq_length = dataset_cleanup(data_path=data_path, \n",
        "                                               min_sent_len=min_sent_len, \n",
        "                                               max_sent_len=max_sent_len)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data for training, consisting of (input,target,teacher) pairs\n",
        "train_data = []\n",
        "for sent in cleaned_data:\n",
        "    train_data.append((sent, sent[1:], sent[:-1]))"
      ],
      "metadata": {
        "id": "24i64kCg-nT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiWQ5WDIrf8d"
      },
      "source": [
        "### **Train word2vec embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2jYEg8J0iNb"
      },
      "source": [
        "We use gensim's word2vec function that trains a skip-gram model (with negative sampling) for 50 epochs to create 256 dimensional word embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2OYup8ZYBcB"
      },
      "outputs": [],
      "source": [
        "word2vec_model = Word2Vec(sentences=cleaned_data, size=EMBEDDING_SIZE, window=5, min_count=1, workers=24, sg=1, negative=50, iter=50)\n",
        "# Save the trained embeddings\n",
        "word2vec_model.save(f\"{path}/Skip-Gram Embeddings/skip-gram_embeddings.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcChWYjyui9I"
      },
      "outputs": [],
      "source": [
        "# Load previously saved embeddings\n",
        "word2vec_model = Word2Vec.load(f\"{path}/Skip-Gram Embeddings/skip-gram_embeddings.model\")\n",
        "\n",
        "print(\"Examine the trained embeddings: \")\n",
        "word2vec_model.most_similar(\"<NUM>\", topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9WYEwEn4K3_"
      },
      "source": [
        "Import custom function that converts the word2vec model word vectors into a numpy matrix that is suitable for insertion into our TensorFlow/Keras embedding layer:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import word2vec_to_matrix"
      ],
      "metadata": {
        "id": "iv47fa0GoYLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix, vocab_size = word2vec_to_matrix(word2vec_model=word2vec_model, embedding_size=EMBEDDING_SIZE)"
      ],
      "metadata": {
        "id": "_Wlh-sBPodWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSeo1hiw7exG"
      },
      "source": [
        "Create a word2index dict in order to convert each token in our train_data dataset to its respective index in the embedding matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_POdYnI2FSQ"
      },
      "outputs": [],
      "source": [
        "word2index_dict = {token: token_index for token_index, token in enumerate(word2vec_model.wv.index2word)}\n",
        "\n",
        "sent2index_input = []\n",
        "sent2index_target = []\n",
        "sent2index_teacher_forcing = []\n",
        "\n",
        "for input, target, teacher in train_data:\n",
        "    input = [word2index_dict[key] for key in input]\n",
        "    target = [word2index_dict[key] for key in target]\n",
        "    teacher = [word2index_dict[key] for key in teacher]\n",
        "    sent2index_input.append(input)\n",
        "    sent2index_target.append(target)\n",
        "    sent2index_teacher_forcing.append(teacher)\n",
        "\n",
        "# Take a look at one input, target, teacher pair\n",
        "print(\"Input sentence: \")\n",
        "print(sent2index_input[0])\n",
        "print(\" \".join([word2vec_model.wv.index2word[i] for i in sent2index_input[0]]))\n",
        "print()\n",
        "print(\"Target sentence: \")\n",
        "print(sent2index_target[0])\n",
        "print(\" \".join([word2vec_model.wv.index2word[i] for i in sent2index_target[0]]))\n",
        "print()\n",
        "print(\"Teacher sentence: \")\n",
        "print(sent2index_teacher_forcing[0])\n",
        "print(\" \".join([word2vec_model.wv.index2word[i] for i in sent2index_teacher_forcing[0]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the indices of the **sos** and **eos** tokens for the inference mode:"
      ],
      "metadata": {
        "id": "eCfWSk05yYum"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYKQTRp83bh4"
      },
      "outputs": [],
      "source": [
        "start_token = word2index_dict[\"<Start>\"]\n",
        "end_token = word2index_dict[\"<End>\"]\n",
        "print(f\"<Start>: {start_token}\")\n",
        "print(f\"<End>: {end_token}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3afipGVpARj8"
      },
      "source": [
        "### **Data Pipeline**\n",
        "Creating tf.Dataset objects that are then cached, shuffled, batched and prefetched for efficient training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6eCrlrKvvFJ"
      },
      "source": [
        "Train data is of form (input, target, teacher), where:\n",
        "\n",
        "\n",
        "*   **Input** contains the sentences that will be fed into the encoder of our AE.\n",
        "\n",
        "*   **Target** contains the sentences that will be used to calculate the loss of our AE.\n",
        "\n",
        "*   **Teacher** contains the sentences that will be used as the input for the decoder during training since we use teacher forcing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l5SSzjTdmF9"
      },
      "outputs": [],
      "source": [
        "# We split the data into train data (85%) and test data (15%)\n",
        "train_dataset_input = tf.data.Dataset.from_tensor_slices(sent2index_input[:int(len(sent2index_input)*0.85)])\n",
        "train_dataset_target = tf.data.Dataset.from_tensor_slices(sent2index_target[:int(len(sent2index_target)*0.85)])\n",
        "train_dataset_teacher = tf.data.Dataset.from_tensor_slices(sent2index_teacher_forcing[:int(len(sent2index_teacher_forcing)*0.85)])\n",
        "\n",
        "train_dataset = tf.data.Dataset.zip((train_dataset_input, train_dataset_target, train_dataset_teacher)).cache().shuffle(buffer_size=500000, reshuffle_each_iteration=True).batch(BATCH_SIZE_AE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "# Repeat for test data\n",
        "test_dataset_input = tf.data.Dataset.from_tensor_slices(sent2index_input[int(len(sent2index_input)*0.85):-1])\n",
        "test_dataset_target = tf.data.Dataset.from_tensor_slices(sent2index_target[int(len(sent2index_target)*0.85):-1])\n",
        "test_dataset_teacher = tf.data.Dataset.from_tensor_slices(sent2index_teacher_forcing[int(len(sent2index_teacher_forcing)*0.85):-1])\n",
        "\n",
        "test_dataset = tf.data.Dataset.zip((test_dataset_input, test_dataset_target, test_dataset_teacher)).cache().shuffle(buffer_size=50000, reshuffle_each_iteration=True).batch(BATCH_SIZE_AE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training: Autoencoder**"
      ],
      "metadata": {
        "id": "hHyZmaUq9NW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from latextgan import AutoEncoder, train_AE"
      ],
      "metadata": {
        "id": "1rz7wkBWCql5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCUagQM3wuBq"
      },
      "source": [
        "Create and train the model:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "News_AE = AutoEncoder(vocab_size=vocab_size, \n",
        "                      embedding_matrix=embedding_matrix, \n",
        "                      embedding_size=EMBEDDING_SIZE, \n",
        "                      hidden_size=HIDDEN_SIZE)"
      ],
      "metadata": {
        "id": "03-Rxr3yO619"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yk1zQHDdcP2"
      },
      "outputs": [],
      "source": [
        "save_path = \"YourPathHere\"\n",
        "save_every = 1 # Number of epochs before saving model weights and plots\n",
        "\n",
        "train_AE(model=News_AE,\n",
        "         word2vec_model=word2vec_model, \n",
        "         save_every=save_every, \n",
        "         save_path=save_path,\n",
        "         train_dataset=train_dataset, \n",
        "         test_dataset=test_dataset, \n",
        "         loss_function=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
        "         num_epochs=NUM_EPOCHS_AE, \n",
        "         learning_rate=LEARNING_RATE_AE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIFCm59WFTNF"
      },
      "source": [
        "## **Training: LaTextGAN**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from latextgan import Generator, Discriminator, train_GAN"
      ],
      "metadata": {
        "id": "FO6bMwvTC3Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h-GwV4F3kUE"
      },
      "source": [
        "Load AutoEncoder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIn1kLoPIXr6",
        "outputId": "dce1dfbb-1002-488f-86f4-6be027dbf8a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f2dc5f3dcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "News_AE = AutoEncoder(vocab_size=vocab_size, \n",
        "                      embedding_matrix=embedding_matrix, \n",
        "                      embedding_size=EMBEDDING_SIZE, \n",
        "                      hidden_size=HIDDEN_SIZE)\n",
        "News_AE.compile()\n",
        "\n",
        "hs = News_AE.Encoder(tf.convert_to_tensor([sent2index_input[-5]]))\n",
        "\n",
        "out = News_AE.Decoder.inference_mode(start_token=start_token, \n",
        "                                     end_token=end_token, \n",
        "                                     max_seq_length=max_seq_length, \n",
        "                                     states=hs)\n",
        "\n",
        "News_AE.load_weights(f\"{path}/Model Weights/Thesis_Model_Weights/AE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBwbM_oEahw5"
      },
      "source": [
        "Create a dataset containing the embeddings of real sentences to train our Discriminator on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZeSH5wJcngR"
      },
      "outputs": [],
      "source": [
        "train_dataset_GAN = train_dataset_input\n",
        "\n",
        "train_dataset_GAN = train_dataset_GAN.map(lambda x: tf.squeeze(News_AE.Encoder(tf.expand_dims(x, axis=0))))\n",
        "\n",
        "train_dataset_GAN = train_dataset_GAN.cache().shuffle(buffer_size=500000, reshuffle_each_iteration=True).batch(BATCH_SIZE_GAN, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternative pipeline that relies on intermediately saving and loading the dataset to free up memory:"
      ],
      "metadata": {
        "id": "4eDjt9lJQ9ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset_GAN = [tf.squeeze(News_AE.Encoder(tf.expand_dims(i, axis=0))) for i in tqdm(train_dataset_input)] \n",
        "\n",
        "# train_dataset_GAN = tf.data.Dataset.from_tensor_slices(train_dataset_GAN)\n",
        "\n",
        "# tf.data.experimental.save(train_dataset_GAN, \"drive/MyDrive/BA_2.0/Dataset/train_dataset_GAN_20\", compression=None, shard_func=None)"
      ],
      "metadata": {
        "id": "HRVceHcu71mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVnVntTUqFVD"
      },
      "outputs": [],
      "source": [
        "# train_dataset_GAN = tf.data.experimental.load(\"drive/MyDrive/BA_2.0/Dataset/train_dataset_GAN_20\", element_spec=None, compression=None, reader_func=None)\n",
        "# train_dataset_GAN = train_dataset_GAN.cache().shuffle(buffer_size=500000, reshuffle_each_iteration=True).batch(BATCH_SIZE_GAN, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0GFm2oN23Op"
      },
      "source": [
        "Create and train the model:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LaTextGAN_Generator = Generator(hidden_size=HIDDEN_SIZE, \n",
        "                                num_res_blocks=NUM_RESIDUAL_BLOCKS)\n",
        "\n",
        "LaTextGAN_Discriminator = Discriminator(hidden_size=HIDDEN_SIZE, \n",
        "                                        num_res_blocks=NUM_RESIDUAL_BLOCKS) "
      ],
      "metadata": {
        "id": "LbP8fh-hWqZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When using the mapping pipeline to create `train_dataset_GAN` the first training epoch may tike quite a while, as every element must actually be fed through the Encoder."
      ],
      "metadata": {
        "id": "0xd-EhlvI4oh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDj8SGenDJ3v",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "save_path = \"YourPathHere\"\n",
        "save_every = 1 # Number of epochs before saving model weights and plots\n",
        "\n",
        "train_GAN(generator=LaTextGAN_Generator,\n",
        "          discriminator=LaTextGAN_Discriminator,\n",
        "          autoencoder=News_AE, \n",
        "          word2vec_model=word2vec_model,\n",
        "          start_token=start_token, \n",
        "          end_token=end_token,  \n",
        "          max_seq_length=max_seq_length,\n",
        "          save_every=save_every, \n",
        "          save_path=save_path,\n",
        "          train_dataset_GAN=train_dataset_GAN, \n",
        "          gen_update=GEN_UPDATE,\n",
        "          num_epochs=NUM_EPOCHS_GAN, \n",
        "          learning_rate=LEARNING_RATE_GAN)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluation**"
      ],
      "metadata": {
        "id": "KeOJwKcOqglm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import evaluation module:"
      ],
      "metadata": {
        "id": "vk_9hs6VclZC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBc-0h9EpUQh"
      },
      "outputs": [],
      "source": [
        "import evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the trained model:"
      ],
      "metadata": {
        "id": "CNwz5xlaqj81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Generator weights\n",
        "LaTextGAN_Generator = Generator(hidden_size=HIDDEN_SIZE, \n",
        "                                num_res_blocks=NUM_RESIDUAL_BLOCKS)\n",
        "LaTextGAN_Generator.compile()\n",
        "\n",
        "LaTextGAN_Generator.load_weights(f\"{path}/Model Weights/Thesis_Model_Weights/LaTextGAN\")"
      ],
      "metadata": {
        "id": "l5akm0IjdsJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Summaries:"
      ],
      "metadata": {
        "id": "38qHTD_OQykF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input, target, teacher in train_dataset.take(1):\n",
        "    News_AE(input, teacher)"
      ],
      "metadata": {
        "id": "E5n5ppgMRNu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "News_AE.Encoder.summary()"
      ],
      "metadata": {
        "id": "TuFvfMnsQ2e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "News_AE.Decoder.summary()"
      ],
      "metadata": {
        "id": "AUGcsC_wSaZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LaTextGAN_Discriminator = Discriminator(hidden_size=HIDDEN_SIZE, \n",
        "                                        num_res_blocks=NUM_RESIDUAL_BLOCKS) \n",
        "\n",
        "for input in train_dataset_GAN.take(1):\n",
        "    LaTextGAN_Generator(tf.random.normal([input.shape[0], HIDDEN_SIZE]))\n",
        "    LaTextGAN_Discriminator(input)"
      ],
      "metadata": {
        "id": "HYC3GrRBS7sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LaTextGAN_Generator.summary()"
      ],
      "metadata": {
        "id": "ktk7NeGkVHMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LaTextGAN_Discriminator.summary()"
      ],
      "metadata": {
        "id": "tnZPFRA_VJAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create csv containing sentences for InferSent: "
      ],
      "metadata": {
        "id": "cmxsr6FfygX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "for _ in tqdm(range(10000)):\n",
        "    sentences.append([word2vec_model.wv.index2word[i.numpy()[0]] for i in News_AE.Decoder.inference_mode(start_token=start_token, \n",
        "                                                                                                         end_token=end_token, \n",
        "                                                                                                         max_seq_length=max_seq_length-1, \n",
        "                                                                                                         states=tf.random.normal([1, HIDDEN_SIZE]))])\n",
        "\n",
        "with open(f\"{path}/Evaluation/FID/News_LaTextGAN_InferSent.csv\", \"w\", encoding='utf8', newline=\"\") as output_file:\n",
        "    writer = csv.writer(output_file)\n",
        "    writer.writerows(sentences)"
      ],
      "metadata": {
        "id": "1QhPpRIdd0NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Sentences:"
      ],
      "metadata": {
        "id": "ecPJV5S8qpwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation.generate_sentences(model=News_AE.Decoder, \n",
        "                              index_decoder=word2vec_model.wv.index2word, \n",
        "                              print_sentences=True, \n",
        "                              model_name=\"News_LaTextGAN\", \n",
        "                              latent_sample_gen=LaTextGAN_Generator, \n",
        "                              num_sent=2, \n",
        "                              start_token=start_token, \n",
        "                              end_token=end_token, \n",
        "                              max_seq_length=max_seq_length)"
      ],
      "metadata": {
        "id": "ftRYMnchsnTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average sentence length:"
      ],
      "metadata": {
        "id": "2EnvqYifKLnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation.generate_sentences(model=News_AE.Decoder, \n",
        "                              index_decoder=word2vec_model.wv.index2word, \n",
        "                              print_sentences=False, \n",
        "                              model_name=\"News_LaTextGAN\", \n",
        "                              latent_sample_gen=LaTextGAN_Generator, \n",
        "                              num_sent=10000, \n",
        "                              start_token=start_token, \n",
        "                              end_token=end_token, \n",
        "                              max_seq_length=max_seq_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "542adc70a96a42278368f516d238a903",
            "fb5dc522882041468e315917648d9017",
            "df814de17c584591b82f9f3336c9bf1e",
            "0525fa64fa374c5bb5110630bac56047",
            "a877d06421d5432393945357cdfb9cfe",
            "d3a6bd00238141439847313511cdc6e8",
            "3d39e1b9991548bb920073687d3df12a",
            "e297e881b3c64e1683612b0dde41804b",
            "839c33a1590f4fe384605822f18bfdc1",
            "e2e4b24aa3294138b0c8d2da8bb7116e",
            "2ecd11ec68184d55a9ad98fb4a89cd3e"
          ]
        },
        "id": "br1roocDKJ9i",
        "outputId": "5f1638aa-eda5-429f-f649-851e352be744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "542adc70a96a42278368f516d238a903"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average length of generated sentences: 18.24 tokens\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the reference data used for Bleu, Self-Bleu and Word Frequency calculations:"
      ],
      "metadata": {
        "id": "IX5-kGgOulnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reference_data = []\n",
        "for sent in sent2index_target[int(len(sent2index_target)*0.85):int(len(sent2index_target)*0.85)+10000]:\n",
        "    temp = []\n",
        "    for token_id in sent:\n",
        "        if token_id == end_token:\n",
        "            break\n",
        "        temp.append(word2vec_model.wv.index2word[token_id])\n",
        "    reference_data.append(temp)"
      ],
      "metadata": {
        "id": "N-LeZRzhu0bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate JS Distance for sentence length frequencies and word counts:"
      ],
      "metadata": {
        "id": "nfmbPBmuzYTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jsd_sents, jsd_words = evaluation.js_distance(model=News_AE.Decoder, \n",
        "                                              index_decoder=word2vec_model.wv.index2word, \n",
        "                                              reference_data=reference_data, \n",
        "                                              model_name=\"News_LaTextGAN\", \n",
        "                                              latent_sample_gen=LaTextGAN_Generator, \n",
        "                                              start_token=start_token, \n",
        "                                              end_token=end_token, \n",
        "                                              max_seq_length=max_seq_length)\n",
        "\n",
        "print(f\"Jensen-Shannon distance for the sentence length frequencies: {jsd_sents}\")\n",
        "print(f\"Jensen-Shannon distance for the word counts: {jsd_words}\")"
      ],
      "metadata": {
        "id": "Ayy1P6N-zaUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Bleu-4 Score:"
      ],
      "metadata": {
        "id": "snlBKLJytG3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation.bleu_score(model=News_AE.Decoder, \n",
        "                      index_decoder=word2vec_model.wv.index2word, \n",
        "                      reference_data=reference_data, \n",
        "                      model_name=\"News_LaTextGAN\", \n",
        "                      latent_sample_gen=LaTextGAN_Generator, \n",
        "                      num_sent=10000, \n",
        "                      n_grams=4, \n",
        "                      start_token=start_token, \n",
        "                      end_token=end_token, \n",
        "                      max_seq_length=max_seq_length)"
      ],
      "metadata": {
        "id": "L0YXG_TEtGRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Self-Bleu-4 Score:"
      ],
      "metadata": {
        "id": "Elgzb12xtLbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation.self_bleu_score(model=News_AE.Decoder, \n",
        "                           index_decoder=word2vec_model.wv.index2word, \n",
        "                           model_name=\"News_LaTextGAN\", \n",
        "                           latent_sample_gen=LaTextGAN_Generator, \n",
        "                           num_sent=10000, \n",
        "                           n_grams=4, \n",
        "                           start_token=start_token, \n",
        "                           end_token=end_token, \n",
        "                           max_seq_length=max_seq_length)"
      ],
      "metadata": {
        "id": "TZMDusShtPSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Word Frequency:"
      ],
      "metadata": {
        "id": "SeD4zCmctP5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 12\n",
        "ref_freq, gen_freq = evaluation.word_freq(model=News_AE.Decoder, \n",
        "                                          index_decoder=word2vec_model.wv.index2word, \n",
        "                                          reference_data=reference_data, \n",
        "                                          model_name=\"News_LaTextGAN\", \n",
        "                                          latent_sample_gen=LaTextGAN_Generator, \n",
        "                                          start_token=start_token, \n",
        "                                          end_token=end_token, \n",
        "                                          max_seq_length=max_seq_length)"
      ],
      "metadata": {
        "id": "Y0nMNpbotT1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(ref_freq.items())[:top_k]"
      ],
      "metadata": {
        "id": "HUfuj3XmvbF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(gen_freq.items())[:top_k]"
      ],
      "metadata": {
        "id": "bhE1E8dkw6R-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word frequency plot:"
      ],
      "metadata": {
        "id": "J83fzRHpHsx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"YourPathHere\"\n",
        "evaluation.word_freq_plots(reference_freq_dict=ref_freq, \n",
        "                           generated_freq_dict=gen_freq, \n",
        "                           top_k=top_k,\n",
        "                           save_plots=False, \n",
        "                           save_path=save_path)"
      ],
      "metadata": {
        "id": "kfDd36BcT4Dy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "542adc70a96a42278368f516d238a903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb5dc522882041468e315917648d9017",
              "IPY_MODEL_df814de17c584591b82f9f3336c9bf1e",
              "IPY_MODEL_0525fa64fa374c5bb5110630bac56047"
            ],
            "layout": "IPY_MODEL_a877d06421d5432393945357cdfb9cfe"
          }
        },
        "fb5dc522882041468e315917648d9017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3a6bd00238141439847313511cdc6e8",
            "placeholder": "​",
            "style": "IPY_MODEL_3d39e1b9991548bb920073687d3df12a",
            "value": "100%"
          }
        },
        "df814de17c584591b82f9f3336c9bf1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e297e881b3c64e1683612b0dde41804b",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_839c33a1590f4fe384605822f18bfdc1",
            "value": 100
          }
        },
        "0525fa64fa374c5bb5110630bac56047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2e4b24aa3294138b0c8d2da8bb7116e",
            "placeholder": "​",
            "style": "IPY_MODEL_2ecd11ec68184d55a9ad98fb4a89cd3e",
            "value": " 100/100 [00:13&lt;00:00,  7.39it/s]"
          }
        },
        "a877d06421d5432393945357cdfb9cfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3a6bd00238141439847313511cdc6e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d39e1b9991548bb920073687d3df12a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e297e881b3c64e1683612b0dde41804b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "839c33a1590f4fe384605822f18bfdc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2e4b24aa3294138b0c8d2da8bb7116e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ecd11ec68184d55a9ad98fb4a89cd3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}